[
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_0_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_0_1.png"
            ],
            "question": "Are both of these images relatively realistic?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Yes\nB: No\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_1_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_1_1.jpg"
            ],
            "question": "Is the first image sharper than the second image?",
            "context": "Candidates: A. Yes B. No"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: overexposure\nB: low light\nC: noise\nD: blur\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_2_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_2_1.jpg"
            ],
            "question": "Which distortion is missing in the second image compared to the first image?",
            "context": "Candidates: A. overexposure B. low light C. noise D. blur"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: The sky in the first image\nB: The figure's back in the second image\nC: The building in the center of the first image\nD: The shop window in the second image\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_3_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_3_1.jpg"
            ],
            "question": "Which part of the two images is more affected by underexposure?",
            "context": "Candidates: A. The sky in the first image B. The figure's back in the second image C. The building in the center of the first image D. The shop window in the second image"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: The ground in the first image\nB: The dog in the first image\nC: The baby in the second image\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_4_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_4_1.JPG"
            ],
            "question": "Which part below is affected by motion blur?",
            "context": "Candidates: A. The ground in the first image B. The dog in the first image C. The baby in the second image"
        },
        "output": {
            "output_text": "C"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Much weaker\nB: About the same\nC: Much stronger\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_5_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_5_1.jpg"
            ],
            "question": "Compared to the second image, how is the lighting in the first image?",
            "context": "Candidates: A. Much weaker B. About the same C. Much stronger"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Similar\nB: Slightly better\nC: Slightly worse\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_6_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_6_1.jpg"
            ],
            "question": "Compared to the second image, how is the lighting situation in the first image?",
            "context": "Candidates: A. Similar B. Slightly better C. Slightly worse"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_7_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_7_1.bmp"
            ],
            "question": "Is the illumination of the second image stronger than the first image?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Yes\nB: No\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_8_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_8_1.jpg"
            ],
            "question": "Is the first image clearer than the second image?",
            "context": "Candidates: A. Yes B. No"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_9_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_9_1.jpg"
            ],
            "question": "Does the first image have more overexposure distortion than the second image?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: The person in the first image\nB: The telephone booth in the first image\nC: The background in the second image\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_10_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_10_1.jpg"
            ],
            "question": "Which part is most affected by motion blur?",
            "context": "Candidates: A. The person in the first image B. The telephone booth in the first image C. The background in the second image"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_11_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_11_1.jpg"
            ],
            "question": "Is the first image more realistic than the second image?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_12_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_12_1.jpg"
            ],
            "question": "Is the lighting of the first image stronger than the second image?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Motion blur\nB: Overexposure\nC: Out of focus\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_13_0.bmp",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_13_1.jpg"
            ],
            "question": "What kind of distortion issue do these two images not have?",
            "context": "Candidates: A. Motion blur B. Overexposure C. Out of focus"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Yes\nB: No\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_14_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_14_1.jpg"
            ],
            "question": "Is the first image more blurry than the second image?",
            "context": "Candidates: A. Yes B. No"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Underexposure\nB: Blur\nC: Motion blur\nD: Overexposure\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_15_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_15_1.jpg"
            ],
            "question": "What problem is not present in the two images?",
            "context": "Candidates: A. Underexposure B. Blur C. Motion blur D. Overexposure"
        },
        "output": {
            "output_text": "C"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Richer\nB: About the same\nC: Less rich\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_16_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_16_1.jpg"
            ],
            "question": "Compared to the first image, how does the texture detail level of the second image look like?",
            "context": "Candidates: A. Richer B. About the same C. Less rich"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: The woman's face in the second image\nB: The blanket in the second image\nC: The grassland background in the first image\nD: The dog's fur in the first image\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_17_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_17_1.jpg"
            ],
            "question": "Which area has clearer details and textures?",
            "context": "Candidates: A. The woman's face in the second image B. The blanket in the second image C. The grassland background in the first image D. The dog's fur in the first image"
        },
        "output": {
            "output_text": "D"
        }
    },
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_18_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_18_1.jpg"
            ],
            "question": "Are the colors of these two images both monotonous?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: The background of the first image\nB: The apple in the first image\nC: The black and white wall of the second image\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_19_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_19_1.jpg"
            ],
            "question": "Which part is most seriously affected by overexposure?",
            "context": "Candidates: A. The background of the first image B. The apple in the first image C. The black and white wall of the second image"
        },
        "output": {
            "output_text": "C"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Yes\nB: No\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_20_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_20_1.jpg"
            ],
            "question": "Is the composition of the first image better than the second image?",
            "context": "Candidates: A. Yes B. No"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: worse\nB: similar\nC: better\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_21_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_21_1.jpg"
            ],
            "question": "Compared to the second image, how is the composition of the first image?",
            "context": "Candidates: A. worse B. similar C. better"
        },
        "output": {
            "output_text": "C"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Blurrier\nB: Clearer\nC: About the same\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_22_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_22_1.jpg"
            ],
            "question": "Relative to the first image, how clear is the second image?",
            "context": "Candidates: A. Blurrier B. Clearer C. About the same"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Less realistic\nB: More realistic\nC: About the same\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_23_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_23_1.jpg"
            ],
            "question": "Compared to the first image, how would you rate the realism of the second image?",
            "context": "Candidates: A. Less realistic B. More realistic C. About the same"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: The left side of the second image\nB: The dog in the second image\nC: The figures in the first image\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_24_0.webp",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_24_1.jpg"
            ],
            "question": "Which part below is most severely affected by overexposure?",
            "context": "Candidates: A. The left side of the second image B. The dog in the second image C. The figures in the first image"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Yes\nB: No\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_25_0.JPG",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_25_1.jpg"
            ],
            "question": "Is the color of the first image more vivid than the second image?",
            "context": "Candidates: A. Yes B. No"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: More realistic\nB: Less realistic\nC: About the same\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_26_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_26_1.jpg"
            ],
            "question": "Compared to the first image, how real is the second image?",
            "context": "Candidates: A. More realistic B. Less realistic C. About the same"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Yes\nB: No\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_27_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_27_1.png"
            ],
            "question": "Is the second image sharper than the first image?",
            "context": "Candidates: A. Yes B. No"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Yes\nB: No\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_28_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_28_1.jpg"
            ],
            "question": "Is the first image blurrier than the second image?",
            "context": "Candidates: A. Yes B. No"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Much worse\nB: About the same\nC: Much better\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_29_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_29_1.jpg"
            ],
            "question": "Compared to the first image, how is the composition of the second image?",
            "context": "Candidates: A. Much worse B. About the same C. Much better"
        },
        "output": {
            "output_text": "C"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Street lamp in the first image\nB: Pedestrian in the second image\nC: Ground in the first image\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_30_0.bmp",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_30_1.bmp"
            ],
            "question": "Which part below is most severely affected by overexposure?",
            "context": "Candidates: A. Street lamp in the first image B. Pedestrian in the second image C. Ground in the first image"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Snowflake\nB: Strong light\nC: Low light\nD: Overexposure\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_31_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_31_1.jpg"
            ],
            "question": "In the problem of which is more severe between the first image and the second image, which of the following is not present?",
            "context": "Candidates: A. Snowflake B. Strong light C. Low light D. Overexposure"
        },
        "output": {
            "output_text": "C"
        }
    },
    {
        "source": "q bench+",
        "options": "A: much worse\nB: almost the same\nC: much worse\nD: much better\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_32_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_32_1.jpg"
            ],
            "question": "Compared to the first image, how is the aesthetic composition of the second image?",
            "context": "Candidates: A. much worse B. almost the same C. much worse D. much better"
        },
        "output": {
            "output_text": "D"
        }
    },
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_33_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_33_1.jpg"
            ],
            "question": "Is the first image sharper than the second image?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Second image\nB: First image\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_34_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_34_1.jpg"
            ],
            "question": "Which image is affected more by overexposure?",
            "context": "Candidates: A. Second image B. First image"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Less rich\nB: About the same\nC: Richer\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_35_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_35_1.jpg"
            ],
            "question": "Compared to the first image, how rich are the texture details in the second image?",
            "context": "Candidates: A. Less rich B. About the same C. Richer"
        },
        "output": {
            "output_text": "C"
        }
    },
    {
        "source": "q bench+",
        "options": "A: About the same\nB: Blurrier\nC: Clearer\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_36_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_36_1.jpg"
            ],
            "question": "Compared to the first image, how is the clarity of the second image?",
            "context": "Candidates: A. About the same B. Blurrier C. Clearer"
        },
        "output": {
            "output_text": "C"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Clearer\nB: Blurrier\nC: About the same\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_37_0.JPG",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_37_1.jpg"
            ],
            "question": "Compared to the first image, how is the clarity of the second image?",
            "context": "Candidates: A. Clearer B. Blurrier C. About the same"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Ground in the first image\nB: Dog in the first image\nC: Person in the second image\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_38_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_38_1.bmp"
            ],
            "question": "Which part below is most affected by motion blur?",
            "context": "Candidates: A. Ground in the first image B. Dog in the first image C. Person in the second image"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: The sky in the second image\nB: The person in the second image\nC: The strawberry in the first image\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_39_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_39_1.jpg"
            ],
            "question": "Which part below is most severely affected by overexposure?",
            "context": "Candidates: A. The sky in the second image B. The person in the second image C. The strawberry in the first image"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Sharper\nB: Blurrier\nC: About the same\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_40_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_40_1.jpg"
            ],
            "question": "Compared to the first image, how is the sharpness of the second image?",
            "context": "Candidates: A. Sharper B. Blurrier C. About the same"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: The focused red flowers in the second image\nB: The flower bush background in the second image\nC: The background in the first image\nD: The man's silhouette in the first image\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_41_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_41_1.JPG"
            ],
            "question": "Which area is more affected by blurring?",
            "context": "Candidates: A. The focused red flowers in the second image B. The flower bush background in the second image C. The background in the first image D. The man's silhouette in the first image"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Second image\nB: First image\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_42_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_42_1.jpg"
            ],
            "question": "Which of the following images has a more serious overexposure issue?",
            "context": "Candidates: A. Second image B. First image"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Yes\nB: No\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_43_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_43_1.jpg"
            ],
            "question": "Is the composition of the first image better than the second image?",
            "context": "Candidates: A. Yes B. No"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Yes\nB: No\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_44_0.webp",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_44_1.png"
            ],
            "question": "Is the second image more realistic than the first image?",
            "context": "Candidates: A. Yes B. No"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_45_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_45_1.jpg"
            ],
            "question": "Is the texture detail of the first image richer than the second image?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: About the same\nB: Slightly sharper\nC: Slightly more blurry\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_46_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_46_1.webp"
            ],
            "question": "Compared to the first image, how is the sharpness of the second image?",
            "context": "Candidates: A. About the same B. Slightly sharper C. Slightly more blurry"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Checkerboard ground in the first image\nB: Horse in the second image\nC: Background in the second image\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_47_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_47_1.jpg"
            ],
            "question": "Which part has the most severe issue of losing texture details?",
            "context": "Candidates: A. Checkerboard ground in the first image B. Horse in the second image C. Background in the second image"
        },
        "output": {
            "output_text": "C"
        }
    },
    {
        "source": "q bench+",
        "options": "A: The ground in the second image\nB: The waves in the first image\nC: The plants in the second image\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_48_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_48_1.jpg"
            ],
            "question": "Which part below is most severely affected by snowflakes?",
            "context": "Candidates: A. The ground in the second image B. The waves in the first image C. The plants in the second image"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_49_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_49_1.jpg"
            ],
            "question": "Are both of these images very clear?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: House windows in the second image\nB: Banana in the first image\nC: Facial features of the person in the first image\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_50_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_50_1.jpg"
            ],
            "question": "Which part below suffers the most severe underexposure problem?",
            "context": "Candidates: A. House windows in the second image B. Banana in the first image C. Facial features of the person in the first image"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Much less\nB: About the same\nC: Much more\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_51_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_51_1.jpg"
            ],
            "question": "How is the noise situation in the second image compared to the first image?",
            "context": "Candidates: A. Much less B. About the same C. Much more"
        },
        "output": {
            "output_text": "C"
        }
    },
    {
        "source": "q bench+",
        "options": "A: the road in the second image\nB: the background of the first image\nC: the ground of the first image\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_52_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_52_1.jpg"
            ],
            "question": "Which part below is most severely affected by snowflake-like distortion?",
            "context": "Candidates: A. the road in the second image B. the background of the first image C. the ground of the first image"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: The floor in the first image\nB: The ground in the second image\nC: The hand holding a gun in the second image\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_53_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_53_1.jpg"
            ],
            "question": "Which part has the richest detail texture?",
            "context": "Candidates: A. The floor in the first image B. The ground in the second image C. The hand holding a gun in the second image"
        },
        "output": {
            "output_text": "C"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Similar\nB: More sufficient\nC: Less sufficient\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_54_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_54_1.jpg"
            ],
            "question": "Compared to the first image, how is the illumination of the second image?",
            "context": "Candidates: A. Similar B. More sufficient C. Less sufficient"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Window in the second image\nB: Aircraft in the first image\nC: Person in the second image\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_55_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_55_1.JPG"
            ],
            "question": "Which part below is most severely affected by overexposure?",
            "context": "Candidates: A. Window in the second image B. Aircraft in the first image C. Person in the second image"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_56_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_56_1.jpg"
            ],
            "question": "Are there severe motion blur in both images?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: The person in red in the second image\nB: The facial part of the person in the first image\nC: The sunglasses in the first image\nD: The top of the tent in the second image\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_57_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_57_1.jpg"
            ],
            "question": "Which part below is most severely affected by overexposure?",
            "context": "Candidates: A. The person in red in the second image B. The facial part of the person in the first image C. The sunglasses in the first image D. The top of the tent in the second image"
        },
        "output": {
            "output_text": "D"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Background of the first image\nB: Character in the second image\nC: Character in the first image\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_58_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_58_1.jpg"
            ],
            "question": "Which part is most severely affected by noise?",
            "context": "Candidates: A. Background of the first image B. Character in the second image C. Character in the first image"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Similar\nB: More Adequate\nC: Less Adequate\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_59_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_59_1.jpg"
            ],
            "question": "Compared to the first image, how is the illumination of the second image?",
            "context": "Candidates: A. Similar B. More Adequate C. Less Adequate"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Similar\nB: Less realistic\nC: More realistic\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_60_0.bmp",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_60_1.jpg"
            ],
            "question": "Compared with the first image, how does the authenticity of the second image differ?",
            "context": "Candidates: A. Similar B. Less realistic C. More realistic"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_61_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_61_1.bmp"
            ],
            "question": "Is the first image more realistic than the second image?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: the top of the first image\nB: bird in the second image\nC: ground in the second image\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_62_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_62_1.png"
            ],
            "question": "Which part below is most affected by overexposure?",
            "context": "Candidates: A. the top of the first image B. bird in the second image C. ground in the second image"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Similar\nB: More fake\nC: More authentic\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_63_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_63_1.webp"
            ],
            "question": "Compared to the second image, how does the first image's authenticity compare?",
            "context": "Candidates: A. Similar B. More fake C. More authentic"
        },
        "output": {
            "output_text": "C"
        }
    },
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_64_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_64_1.png"
            ],
            "question": "Is the first image clearer than the second image?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_65_0.webp",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_65_1.jpg"
            ],
            "question": "Are the details and textures in the first image clearer than those in the second image?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: More blurry\nB: Clearer\nC: About the same\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_66_0.bmp",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_66_1.JPG"
            ],
            "question": "Compared to the first image, how is the sharpness of the second image?",
            "context": "Candidates: A. More blurry B. Clearer C. About the same"
        },
        "output": {
            "output_text": "C"
        }
    },
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_67_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_67_1.JPG"
            ],
            "question": "Are the two images both quite clear?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_68_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_68_1.jpg"
            ],
            "question": "Is the first image sharper than the second image?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_69_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_69_1.jpg"
            ],
            "question": "Are there noise issues in both of these images?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Much more severe\nB: Similar\nC: Much slighter\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_70_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_70_1.jpg"
            ],
            "question": "How does the noise situation in the second image compare to the first image?",
            "context": "Candidates: A. Much more severe B. Similar C. Much slighter"
        },
        "output": {
            "output_text": "C"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Much worse\nB: Much better\nC: About the same\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_71_0.JPG",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_71_1.jpg"
            ],
            "question": "Compared to the first image, how is the focusing situation of the second image?",
            "context": "Candidates: A. Much worse B. Much better C. About the same"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: More authentic\nB: About the same\nC: Less authentic\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_72_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_72_1.png"
            ],
            "question": "Compared to the first image, how does the authenticity of the second image compare?",
            "context": "Candidates: A. More authentic B. About the same C. Less authentic"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Yes\nB: No\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_73_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_73_1.jpg"
            ],
            "question": "Compared to the second image, is the detail texture of the first image clearer?",
            "context": "Candidates: A. Yes B. No"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Similar\nB: Much worse\nC: Much better\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_74_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_74_1.jpg"
            ],
            "question": "How is the focus of the second image relative to the first image?",
            "context": "Candidates: A. Similar B. Much worse C. Much better"
        },
        "output": {
            "output_text": "C"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Underexposure\nB: Motion blur\nC: Overexposure\nD: Blur\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_75_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_75_1.jpg"
            ],
            "question": "Which kind of distortion is not present in the two images?",
            "context": "Candidates: A. Underexposure B. Motion blur C. Overexposure D. Blur"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Overexposure\nB: Focus problem\nC: Noise\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_76_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_76_1.jpg"
            ],
            "question": "What is the distortion that does not appear in the two images?",
            "context": "Candidates: A. Overexposure B. Focus problem C. Noise"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: First image\nB: Second image\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_77_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_77_1.jpg"
            ],
            "question": "Which image does not have overexposure distortion issue?",
            "context": "Candidates: A. First image B. Second image"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Yes\nB: No\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_78_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_78_1.jpg"
            ],
            "question": "Is the focus of the first image not as good as the second image?",
            "context": "Candidates: A. Yes B. No"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: About the same\nB: Clearer\nC: Blurrier\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_79_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_79_1.jpg"
            ],
            "question": "Compared to the first image, how clear are the texture details of the subject in the second image?",
            "context": "Candidates: A. About the same B. Clearer C. Blurrier"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: About the same\nB: Much clearer\nC: Much blurrier\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_80_0.bmp",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_80_1.jpg"
            ],
            "question": "Compared to the first image, how is the clarity of texture details in the second image?",
            "context": "Candidates: A. About the same B. Much clearer C. Much blurrier"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: The wall in the first image\nB: The large tree on the right side in the second image\nC: The street light in the second image\nD: The clothes hanger in the first image\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_81_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_81_1.jpg"
            ],
            "question": "Which part below is most affected by overexposure?",
            "context": "Candidates: A. The wall in the first image B. The large tree on the right side in the second image C. The street light in the second image D. The clothes hanger in the first image"
        },
        "output": {
            "output_text": "C"
        }
    },
    {
        "source": "q bench+",
        "options": "A: About the same\nB: More blurry\nC: Clearer\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_82_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_82_1.jpg"
            ],
            "question": "Compared to the first image, how is the clarity of the second image?",
            "context": "Candidates: A. About the same B. More blurry C. Clearer"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Less authentic\nB: About the same\nC: More authentic\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_83_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_83_1.jpg"
            ],
            "question": "Compared to the first image, how is the authenticity of the second image?",
            "context": "Candidates: A. Less authentic B. About the same C. More authentic"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Yes\nB: No\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_84_0.JPG",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_84_1.bmp"
            ],
            "question": "Is the first image sharper than the second image?",
            "context": "Candidates: A. Yes B. No"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Less real\nB: About the same\nC: More real\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_85_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_85_1.jpg"
            ],
            "question": "Compared to the first image, how does the reality of the second image compare?",
            "context": "Candidates: A. Less real B. About the same C. More real"
        },
        "output": {
            "output_text": "C"
        }
    },
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_86_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_86_1.bmp"
            ],
            "question": "Is the noise in the first image much more obvious than in the second image?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Similar\nB: More realistic\nC: Less realistic\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_87_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_87_1.jpg"
            ],
            "question": "How does the realism of the second image compare to the first image?",
            "context": "Candidates: A. Similar B. More realistic C. Less realistic"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Yes\nB: No\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_88_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_88_1.jpg"
            ],
            "question": "Are both images not genuine?",
            "context": "Candidates: A. Yes B. No"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Yes\nB: No\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_89_0.webp",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_89_1.jpg"
            ],
            "question": "Is the first image more realistic than the second image?",
            "context": "Candidates: A. Yes B. No"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: More blurry\nB: Clearer\nC: About the same\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_90_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_90_1.jpg"
            ],
            "question": "Compared to the first image, how is the clarity of the second image?",
            "context": "Candidates: A. More blurry B. Clearer C. About the same"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Much higher\nB: About the same\nC: Much lower\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_91_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_91_1.jpg"
            ],
            "question": "Compared to the second image, how is the pixel quality of the first image?",
            "context": "Candidates: A. Much higher B. About the same C. Much lower"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Slightly more\nB: More severe\nC: About the same\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_92_0.webp",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_92_1.jpg"
            ],
            "question": "Compared to the first image, how much is the second image affected by motion blur?",
            "context": "Candidates: A. Slightly more B. More severe C. About the same"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Yes\nB: No\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_93_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_93_1.jpg"
            ],
            "question": "Is the first image clearer than the second image?",
            "context": "Candidates: A. Yes B. No"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Similar\nB: More realistic\nC: Less realistic\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_94_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_94_1.jpg"
            ],
            "question": "How does the realism of the second image compare to the first image?",
            "context": "Candidates: A. Similar B. More realistic C. Less realistic"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_95_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_95_1.jpg"
            ],
            "question": "Is the first image sharper than the second image?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Yes\nB: No\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_96_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_96_1.jpg"
            ],
            "question": "Is the color of the first image more rich and vivid than the second image?",
            "context": "Candidates: A. Yes B. No"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Yes\nB: No\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_97_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_97_1.jpg"
            ],
            "question": "Is the first image significantly less clear than the second image?",
            "context": "Candidates: A. Yes B. No"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: The sky in the upper right corner of the second image\nB: The buildings in the second image\nC: The lake surface in the first image\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_98_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_98_1.png"
            ],
            "question": "Which part below has the most severe overexposure?",
            "context": "Candidates: A. The sky in the upper right corner of the second image B. The buildings in the second image C. The lake surface in the first image"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: More abundant\nB: Less abundant\nC: About the same\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_99_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_99_1.jpg"
            ],
            "question": "Compared to the first image, how is the texture detail in the second image?",
            "context": "Candidates: A. More abundant B. Less abundant C. About the same"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Background of the first image\nB: Stamen of the second image\nC: Person in the first image\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_100_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_100_1.JPG"
            ],
            "question": "Which part below is most severely affected by out-of-focus?",
            "context": "Candidates: A. Background of the first image B. Stamen of the second image C. Person in the first image"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Underexposed\nB: Blurry\nC: Motion blur\nD: Overexposed\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_101_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_101_1.jpg"
            ],
            "question": "Compared to the second image, what kind of distortion does the first image not have?",
            "context": "Candidates: A. Underexposed B. Blurry C. Motion blur D. Overexposed"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: More blurry\nB: About the same\nC: Clearer\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_102_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_102_1.png"
            ],
            "question": "Compared to the first image, how is the clarity of the subject's details and textures in the second image?",
            "context": "Candidates: A. More blurry B. About the same C. Clearer"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Lens flare\nB: Motion blur\nC: Overexposure\nD: Noise\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_103_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_103_1.jpg"
            ],
            "question": "What kind of distortion do not appear in these two images?",
            "context": "Candidates: A. Lens flare B. Motion blur C. Overexposure D. Noise"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Blur\nB: Motion blur\nC: Underexposure\nD: Overexposure\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_104_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_104_1.jpg"
            ],
            "question": "What kind of distortion is not present in the two images?",
            "context": "Candidates: A. Blur B. Motion blur C. Underexposure D. Overexposure"
        },
        "output": {
            "output_text": "D"
        }
    },
    {
        "source": "q bench+",
        "options": "A: richer\nB: about the same\nC: more monotonous\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_105_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_105_1.jpg"
            ],
            "question": "Compared to the first image, how rich is the color in the second image?",
            "context": "Candidates: A. richer B. about the same C. more monotonous"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Yes\nB: No\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_106_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_106_1.jpg"
            ],
            "question": "Is the color of the first image richer than the second image?",
            "context": "Candidates: A. Yes B. No"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_107_0.bmp",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_107_1.jpg"
            ],
            "question": "Is the sharpness of the first image lower than the second image?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Yes\nB: No\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_108_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_108_1.jpg"
            ],
            "question": "Is the color of the first image richer than the second image?",
            "context": "Candidates: A. Yes B. No"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Similar\nB: Worse\nC: Better\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_109_0.bmp",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_109_1.jpg"
            ],
            "question": "How does the composition of the second image compare to the first image?",
            "context": "Candidates: A. Similar B. Worse C. Better"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: The sky in the first image\nB: The person in the first image\nC: The bus in the second image\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_110_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_110_1.jpg"
            ],
            "question": "Which part below is most affected by noise?",
            "context": "Candidates: A. The sky in the first image B. The person in the first image C. The bus in the second image"
        },
        "output": {
            "output_text": "C"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Underexposure\nB: Low light\nC: Out of focus\nD: Noise\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_111_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_111_1.jpg"
            ],
            "question": "Which type of distortion is more severe in the second image compared to the first image?",
            "context": "Candidates: A. Underexposure B. Low light C. Out of focus D. Noise"
        },
        "output": {
            "output_text": "C"
        }
    },
    {
        "source": "q bench+",
        "options": "A: More severe\nB: Slightly more\nC: About the same\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_112_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_112_1.jpg"
            ],
            "question": "Compared to the second image, how is the first image affected by underexposure?",
            "context": "Candidates: A. More severe B. Slightly more C. About the same"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_113_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_113_1.webp"
            ],
            "question": "Are both of these images very realistic?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_114_0.JPG",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_114_1.jpg"
            ],
            "question": "Is the illumination sufficient in both of these images?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Yes\nB: No\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_115_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_115_1.jpg"
            ],
            "question": "Is the first image sharper than the second image?",
            "context": "Candidates: A. Yes B. No"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: similar\nB: less rich\nC: richer\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_116_0.JPG",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_116_1.jpg"
            ],
            "question": "Compared to the first image, how is the texture detail of the second image?",
            "context": "Candidates: A. similar B. less rich C. richer"
        },
        "output": {
            "output_text": "C"
        }
    },
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_117_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_117_1.jpg"
            ],
            "question": "Is the color of the first image more vivid than the second image?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_118_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_118_1.jpg"
            ],
            "question": "Is the first image clearer than the second image?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Front building in the second image\nB: Aircraft in the first image\nC: Left sky in the second image\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_119_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_119_1.jpg"
            ],
            "question": "Which part below is most affected by overexposure?",
            "context": "Candidates: A. Front building in the second image B. Aircraft in the first image C. Left sky in the second image"
        },
        "output": {
            "output_text": "C"
        }
    },
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_120_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_120_1.jpg"
            ],
            "question": "Is the noise in the first image significantly more severe than in the second image?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_121_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_121_1.webp"
            ],
            "question": "Is the first image clearer than the second image?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Characters in the first image\nB: Top right corner of the second image\nC: Ground in the first image\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_122_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_122_1.jpg"
            ],
            "question": "Which part below is most affected by overexposure?",
            "context": "Candidates: A. Characters in the first image B. Top right corner of the second image C. Ground in the first image"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: First image\nB: Second image\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_123_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_123_1.jpg"
            ],
            "question": "Which of the following images is most affected by motion blur?",
            "context": "Candidates: A. First image B. Second image"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_124_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_124_1.bmp"
            ],
            "question": "Is the illumination sufficient in these two images?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Yes\nB: No\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_125_0.webp",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_125_1.png"
            ],
            "question": "Is the fidelity of the first image lower than the second image?",
            "context": "Candidates: A. Yes B. No"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Yes\nB: No\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_126_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_126_1.jpg"
            ],
            "question": "Are both of these images clear?",
            "context": "Candidates: A. Yes B. No"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Background of the first image\nB: Background of the second image\nC: Person in the first image\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_127_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_127_1.jpg"
            ],
            "question": "Which part below is most severely affected by motion blur?",
            "context": "Candidates: A. Background of the first image B. Background of the second image C. Person in the first image"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Similar\nB: More blurry\nC: Clearer\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_128_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_128_1.bmp"
            ],
            "question": "Compared to the first image, how is the clarity of the second image?",
            "context": "Candidates: A. Similar B. More blurry C. Clearer"
        },
        "output": {
            "output_text": "C"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Similar\nB: Clearer\nC: Blurrier\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_129_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_129_1.jpg"
            ],
            "question": "How does the clarity of the second image compare to the first image?",
            "context": "Candidates: A. Similar B. Clearer C. Blurrier"
        },
        "output": {
            "output_text": "C"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Yes\nB: No\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_130_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_130_1.webp"
            ],
            "question": "Are both images rich in color?",
            "context": "Candidates: A. Yes B. No"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Second image\nB: First image\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_131_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_131_1.webp"
            ],
            "question": "Which of the following images has a serious overexposure issue?",
            "context": "Candidates: A. Second image B. First image"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Yes\nB: No\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_132_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_132_1.jpg"
            ],
            "question": "Are the colors of these two images not very vivid?",
            "context": "Candidates: A. Yes B. No"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Much better\nB: Much worse\nC: About the same\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_133_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_133_1.jpg"
            ],
            "question": "Compared to the first image, how rich are the colors in the second image?",
            "context": "Candidates: A. Much better B. Much worse C. About the same"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Slightly worse\nB: Slightly better\nC: Much worse\nD: About the same\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_134_0.JPG",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_134_1.jpg"
            ],
            "question": "Compared to the lighting of the second image, how is the lighting of the first image?",
            "context": "Candidates: A. Slightly worse B. Slightly better C. Much worse D. About the same"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_135_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_135_1.jpg"
            ],
            "question": "Are both of these images clear?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Ground in the first image\nB: Car in the first image\nC: Plane in the second image\nD: Background in the second image\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_136_0.bmp",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_136_1.jpg"
            ],
            "question": "Which area is more affected by motion blur?",
            "context": "Candidates: A. Ground in the first image B. Car in the first image C. Plane in the second image D. Background in the second image"
        },
        "output": {
            "output_text": "D"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Yes\nB: No\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_137_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_137_1.jpg"
            ],
            "question": "Is the lighting of the first image more sufficient than the second image?",
            "context": "Candidates: A. Yes B. No"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_138_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_138_1.webp"
            ],
            "question": "Are both images very real?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Yes\nB: No\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_139_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_139_1.jpg"
            ],
            "question": "Are both of these images relatively blurry?",
            "context": "Candidates: A. Yes B. No"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: The player in the first image\nB: The horse in the second image\nC: The audience in the background of the first image\nD: The background in the second image\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_140_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_140_1.jpg"
            ],
            "question": "In which area of the two images is more affected by motion blur?",
            "context": "Candidates: A. The player in the first image B. The horse in the second image C. The audience in the background of the first image D. The background in the second image"
        },
        "output": {
            "output_text": "D"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Ground of the second image\nB: Sky of the second image\nC: Ground of the first image\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_141_0.JPG",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_141_1.jpg"
            ],
            "question": "Which part has the most severe overexposure issue?",
            "context": "Candidates: A. Ground of the second image B. Sky of the second image C. Ground of the first image"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_142_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_142_1.jpg"
            ],
            "question": "Is the first image more realistic than the second image?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Yes\nB: No\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_143_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_143_1.jpg"
            ],
            "question": "Is the first image sharper than the second image?",
            "context": "Candidates: A. Yes B. No"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: About the same\nB: Much blurrier\nC: Much clearer\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_144_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_144_1.jpg"
            ],
            "question": "Compared to the first image, how is the clarity of the second image?",
            "context": "Candidates: A. About the same B. Much blurrier C. Much clearer"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Background of the second image\nB: Table in front of the second image\nC: Grass in the first image\nD: Snowy mountain in the first image\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_145_0.JPG",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_145_1.webp"
            ],
            "question": "Which area is more severely affected by blurring?",
            "context": "Candidates: A. Background of the second image B. Table in front of the second image C. Grass in the first image D. Snowy mountain in the first image"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: The ground in the second image\nB: The person in the second image\nC: The person in the first image\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_146_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_146_1.jpg"
            ],
            "question": "Which part below is most affected by motion blur?",
            "context": "Candidates: A. The ground in the second image B. The person in the second image C. The person in the first image"
        },
        "output": {
            "output_text": "C"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Similar\nB: Slightly smaller\nC: Significantly larger\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_147_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_147_1.jpg"
            ],
            "question": "Compared to the first image, how is the second image affected by overexposure?",
            "context": "Candidates: A. Similar B. Slightly smaller C. Significantly larger"
        },
        "output": {
            "output_text": "C"
        }
    },
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_148_0.png",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_148_1.jpg"
            ],
            "question": "Is the first image sharper than the second image?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Less rich\nB: About the same\nC: Richer\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_149_0.JPG",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_149_1.jpg"
            ],
            "question": "Compared to the first image, how is the color richness of the second image?",
            "context": "Candidates: A. Less rich B. About the same C. Richer"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Much poorer\nB: Much richer\nC: About the same\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_150_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_150_1.jpg"
            ],
            "question": "Compared to the first image, how is the richness of colors in the second image?",
            "context": "Candidates: A. Much poorer B. Much richer C. About the same"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Similar\nB: Better\nC: Worse\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_151_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_151_1.jpg"
            ],
            "question": "Compared to the first photo, how is the focus of the second photo?",
            "context": "Candidates: A. Similar B. Better C. Worse"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_152_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_152_1.jpg"
            ],
            "question": "Is the composition of the first image better than the second image?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: More monotonous\nB: About the same\nC: More rich\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_153_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_153_1.jpg"
            ],
            "question": "Compared to the first image, how is the color richness of the second image?",
            "context": "Candidates: A. More monotonous B. About the same C. More rich"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Similar\nB: Clearer\nC: Blurrier\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_154_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_154_1.jpg"
            ],
            "question": "Compared to the first image, how is the clarity of the second image?",
            "context": "Candidates: A. Similar B. Clearer C. Blurrier"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Ground in the first image\nB: Sky in the second image\nC: Lion in the first image\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_155_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_155_1.jpg"
            ],
            "question": "Which part below is most severely affected by overexposure?",
            "context": "Candidates: A. Ground in the first image B. Sky in the second image C. Lion in the first image"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: More authentic\nB: About the same\nC: Less authentic\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_156_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_156_1.jpg"
            ],
            "question": "Compared to the first image, how would you rate the authenticity of the second image?",
            "context": "Candidates: A. More authentic B. About the same C. Less authentic"
        },
        "output": {
            "output_text": "C"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Yes\nB: No\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_157_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_157_1.jpg"
            ],
            "question": "Are both of these images very clear?",
            "context": "Candidates: A. Yes B. No"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_158_0.bmp",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_158_1.JPG"
            ],
            "question": "Have both figures in these two images been overexposed?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Area in the first image\nB: Roof of the building in the second image\nC: Athlete in the first image\nD: Sky in the second image\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_159_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_159_1.jpg"
            ],
            "question": "Which area is most affected by overexposure?",
            "context": "Candidates: A. Area in the first image B. Roof of the building in the second image C. Athlete in the first image D. Sky in the second image"
        },
        "output": {
            "output_text": "D"
        }
    },
    {
        "source": "q bench+",
        "options": "A: The moon in the second image\nB: The person in the bottom right corner of the first image\nC: The left sky in the first image\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_160_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_160_1.jpg"
            ],
            "question": "Which part below is most affected by overexposure?",
            "context": "Candidates: A. The moon in the second image B. The person in the bottom right corner of the first image C. The left sky in the first image"
        },
        "output": {
            "output_text": "C"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Yes\nB: No\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_161_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_161_1.bmp"
            ],
            "question": "Is the texture detail of the first image less rich than the second image?",
            "context": "Candidates: A. Yes B. No"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Less real\nB: About the same\nC: More real\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_162_0.webp",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_162_1.jpg"
            ],
            "question": "Compared to the first image, how real is the second image?",
            "context": "Candidates: A. Less real B. About the same C. More real"
        },
        "output": {
            "output_text": "C"
        }
    },
    {
        "source": "q bench+",
        "options": "A: About the same\nB: More blurry\nC: Clearer\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_163_0.webp",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_163_1.webp"
            ],
            "question": "Compared to the first image, how clear is the second image?",
            "context": "Candidates: A. About the same B. More blurry C. Clearer"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Low light\nB: Vignetting\nC: Noise\nD: Motion blur\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_164_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_164_1.jpg"
            ],
            "question": "Which type of distortion does not appear in the two images?",
            "context": "Candidates: A. Low light B. Vignetting C. Noise D. Motion blur"
        },
        "output": {
            "output_text": "C"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Out of focus\nB: Noise\nC: Overexposure\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_165_0.bmp",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_165_1.JPG"
            ],
            "question": "What kind of distortion did not appear in these two images?",
            "context": "Candidates: A. Out of focus B. Noise C. Overexposure"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: overexposure\nB: motion blur\nC: out of focus\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_166_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_166_1.jpg"
            ],
            "question": "Are there any distortion issues in these two images?",
            "context": "Candidates: A. overexposure B. motion blur C. out of focus"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Yes\nB: No\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_167_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_167_1.jpg"
            ],
            "question": "Is the noise in the first image larger than the second image?",
            "context": "Candidates: A. Yes B. No"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_168_0.bmp",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_168_1.jpg"
            ],
            "question": "Is the sky in the second image more affected by overexposure than the sky in the first image?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Less sufficient\nB: About the same\nC: More sufficient\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_169_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_169_1.jpg"
            ],
            "question": "Compared to the first image, how is the lighting in the second image?",
            "context": "Candidates: A. Less sufficient B. About the same C. More sufficient"
        },
        "output": {
            "output_text": "C"
        }
    },
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_170_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_170_1.JPG"
            ],
            "question": "Is the first image blurrier than the second image?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_171_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_171_1.jpg"
            ],
            "question": "Is the first image sharper than the second image?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Much clearer\nB: About the same\nC: Much blurrier\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_172_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_172_1.jpg"
            ],
            "question": "Compared to the second image, how is the fine texture of the first image?",
            "context": "Candidates: A. Much clearer B. About the same C. Much blurrier"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Less sufficient\nB: More sufficient\nC: About the same\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_173_0.bmp",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_173_1.jpg"
            ],
            "question": "How does the illumination of the second image compare to the first image?",
            "context": "Candidates: A. Less sufficient B. More sufficient C. About the same"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Low light\nB: Blur\nC: Motion blur\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_174_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_174_1.JPG"
            ],
            "question": "What problems are not present in the two images?",
            "context": "Candidates: A. Low light B. Blur C. Motion blur"
        },
        "output": {
            "output_text": "C"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Motion blur\nB: Underexposure\nC: Overexposure\nD: Weak light\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_175_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_175_1.jpg"
            ],
            "question": "Which of the following distortions does not appear in the two images?",
            "context": "Candidates: A. Motion blur B. Underexposure C. Overexposure D. Weak light"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Yes\nB: No\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_176_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_176_1.jpg"
            ],
            "question": "Is the illumination sufficient in both of these images?",
            "context": "Candidates: A. Yes B. No"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_177_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_177_1.jpg"
            ],
            "question": "Is the first image sharper than the second image?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Yes\nB: No\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_178_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_178_1.webp"
            ],
            "question": "Is the second image more realistic than the first image?",
            "context": "Candidates: A. Yes B. No"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Blur\nB: Overexposure\nC: Underexposure\nD: Noise\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_179_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_179_1.jpg"
            ],
            "question": "Please identify what kind of distortion is not present in these two images?",
            "context": "Candidates: A. Blur B. Overexposure C. Underexposure D. Noise"
        },
        "output": {
            "output_text": "C"
        }
    },
    {
        "source": "q bench+",
        "options": "A: similar\nB: more realistic\nC: less realistic\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_180_0.webp",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_180_1.jpg"
            ],
            "question": "Compared to the first image, how is the realism of the second image?",
            "context": "Candidates: A. similar B. more realistic C. less realistic"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Yes\nB: No\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_181_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_181_1.jpg"
            ],
            "question": "Is the first image more realistic?",
            "context": "Candidates: A. Yes B. No"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Second image\nB: First image\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_182_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_182_1.jpg"
            ],
            "question": "Which image below is more severely affected by overexposure?",
            "context": "Candidates: A. Second image B. First image"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Similar\nB: Worse\nC: Better\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_183_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_183_1.jpg"
            ],
            "question": "How does the composition of the second image compare to the first image?",
            "context": "Candidates: A. Similar B. Worse C. Better"
        },
        "output": {
            "output_text": "C"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Very dark\nB: Much darker\nC: Much brighter\nD: About the same\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_184_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_184_1.jpg"
            ],
            "question": "Compared to the first image, how is the lighting in the second image?",
            "context": "Candidates: A. Very dark B. Much darker C. Much brighter D. About the same"
        },
        "output": {
            "output_text": "C"
        }
    },
    {
        "source": "q bench+",
        "options": "A: The man in front of the lens in the first picture\nB: The bus in the first picture\nC: The fish in the second picture\nD: The leaves in the background of the second picture\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_185_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_185_1.bmp"
            ],
            "question": "Which area is more affected by low light?",
            "context": "Candidates: A. The man in front of the lens in the first picture B. The bus in the first picture C. The fish in the second picture D. The leaves in the background of the second picture"
        },
        "output": {
            "output_text": "D"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Much better\nB: Much worse\nC: About the same\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_186_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_186_1.jpg"
            ],
            "question": "Compared to the first image, how is the sharpness of the second image?",
            "context": "Candidates: A. Much better B. Much worse C. About the same"
        },
        "output": {
            "output_text": "C"
        }
    },
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_187_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_187_1.jpg"
            ],
            "question": "Are both of these images very blurry?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_188_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_188_1.jpg"
            ],
            "question": "Are both of these images not very clear?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: The person riding a bike in the first image\nB: The background of the first image\nC: The plant in the second image\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_189_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_189_1.jpg"
            ],
            "question": "Which part below is most severely affected by motion blur?",
            "context": "Candidates: A. The person riding a bike in the first image B. The background of the first image C. The plant in the second image"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_190_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_190_1.jpg"
            ],
            "question": "Compared to the second image, is the first image more affected by motion blur?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: More monotonous\nB: About the same\nC: More rich\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_191_0.JPG",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_191_1.jpg"
            ],
            "question": "Compared to the first image, what is the color vividness of the second image?",
            "context": "Candidates: A. More monotonous B. About the same C. More rich"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Yes\nB: No\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_192_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_192_1.jpg"
            ],
            "question": "Is the first image sharper than the second image?",
            "context": "Candidates: A. Yes B. No"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: the yellow doll in the first image\nB: the street lamp in the second image\nC: the wall in the first image\nD: the vehicle in the second image\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_193_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_193_1.jpg"
            ],
            "question": "Which part below is most affected by overexposure?",
            "context": "Candidates: A. the yellow doll in the first image B. the street lamp in the second image C. the wall in the first image D. the vehicle in the second image"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_194_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_194_1.jpg"
            ],
            "question": "Is the detail texture of the second image clearer than the first image?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_195_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_195_1.jpg"
            ],
            "question": "Is the first image more realistic than the second image?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_196_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_196_1.JPG"
            ],
            "question": "Is the color of the first image richer than the second image?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: Yes\nB: No\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_197_0.JPG",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_197_1.jpg"
            ],
            "question": "Is the first image more authentic than the second image?",
            "context": "Candidates: A. Yes B. No"
        },
        "output": {
            "output_text": "A"
        }
    },
    {
        "source": "q bench+",
        "options": "A: worse\nB: better\nC: similar\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_198_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_198_1.jpg"
            ],
            "question": "How does the lighting of the second image compare to the first image?",
            "context": "Candidates: A. worse B. better C. similar"
        },
        "output": {
            "output_text": "B"
        }
    },
    {
        "source": "q bench+",
        "options": "A: No\nB: Yes\n",
        "visual_input_component": "natural image",
        "input": {
            "input_image_path": [
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_199_0.jpg",
                "/mnt/hwfile/gveval/mengfanqing/MMIU/Low-level-semantic/visual_quality_assessment_q_bench+/visual_quality_assessment_q_bench+_199_1.jpg"
            ],
            "question": "Is the focus of the first image better than the second image?",
            "context": "Candidates: A. No B. Yes"
        },
        "output": {
            "output_text": "A"
        }
    }
]